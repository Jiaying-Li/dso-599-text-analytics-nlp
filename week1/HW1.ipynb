{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 (Due 5:30pm PST March 19th, 2019): Naive Bayes and Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Compute the following probabilities and state what type of probability (marginal, joint, conditional) (4 points):**\n",
    "```python\n",
    "corpus = [(\"I love going to class\", \"ham\"),\n",
    "(\"Class is going well\", \"ham\"),\n",
    "(\"Do you love bargains\", \"spam\"),\n",
    "(\"Act now for bargains\", \"spam\"),\n",
    "(\"I love you\", \"ham\")]\n",
    "```\n",
    "* P(x = love | y = ham)\n",
    "* P(y = spam)\n",
    "* P(x = bargains)\n",
    "* P(y = ham | x = \"You love bargains\")\n",
    "\n",
    "**B. Former In-Class Exercise Word Count (Now Homework 1B) - 6 points**\n",
    "\n",
    "You are a business analyst working for a major US toy retailer:\n",
    "\n",
    "* Part 1: A manager in the marketing department wants to find out the most frequently used words in positive reviews (five stars) and negative reviews (one star) in order to determine who the toys are being bought for (sons, significant others, grandchildren, siblings, self, etc.). He would like your opinion on which customer segments' (son, daughter, granddaugher, grandson, niece, nephew, sibling, significant other, etc.) marketing messaging tends to outperform other segments.\n",
    "\n",
    "* Part 2: One of your product managers suspects that **toys with batteries tend to be significantly lower rated than toys that do not require batteries**. She would like to see some data points confirming or rejecting her hypothesis. \n",
    "\n",
    "Perform the same word count analysis using the reviews received from Amazon to answer your marketing manager's and product manager's question. They are stored in two files, (`poor_amazon_toy_reviews.txt`) and (`good-amazon-toy-reviews.txt`). **Provide only few sentences with your findings and business recommendations for each part (Part A and B.** Make any assumptions you'd like to- this is a fictitious company after all. I just want you to get into the habit of \"finishing\" your analysis: to avoid delivering technical numbers to a non-technical manager.\n",
    "\n",
    "**C. Read \"What is Natural Language Processing? The Business Use Case Explained\" (CIO.com) and Intro to Algorithmic Marketing (pages 179 - 184, 193 - 201)**. Be prepared for a short in-class graded exercise at the beginning of Week 2 on the topics in these readings (read it once, don't read it twice).\n",
    "\n",
    "\n",
    "\n",
    "### **Submit everything as a new notebook, either via Slack direct message to me, or email to me (ychen220@usc.edu). Much of the code should already be written for you!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "poor = open(\"poor_amazon_toy_reviews.txt\")\n",
    "good = open(\"good_amazon_toy_reviews.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "poor_lines = poor.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_lines = good.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lines = poor_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(\"I hate this show. I love that show\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I hate this show . I love that show'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12700"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\"hello there\", \"goodbye for the a on you it now\"]\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'hate', 'this', 'show', '.', 'I', 'love', 'that', 'show']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentence = []\n",
    "for token in tokens:\n",
    "    if token not in stopwords:\n",
    "        new_sentence.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. import data\n",
    "2. each review -> sentences -> tokens (word)\n",
    "3. each word -> lemmatize/stem -> list of cleaned words\n",
    "4. join the list of cleaned words together to create a string sentence\n",
    "5. pass into countvectorizer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
